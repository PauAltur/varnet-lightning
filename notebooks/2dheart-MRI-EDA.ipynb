{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore 2D+t Heart MRI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "from projectB.utils.plotting import PlotUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from mat file\n",
    "data = loadmat(\"../data/raw/2dt_heart.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the images\n",
    "videos = data[\"imgs\"]\n",
    "videos = np.moveaxis(videos, (2, 3), (1, 0))\n",
    "videos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the video grid\n",
    "sampled_indices = np.random.choice(videos.shape[0], 16, replace=False)\n",
    "PlotUtils.display_video_grid(\n",
    "    videos[sampled_indices], grid_size=(4, 4), figsize=(24, 24)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fourier Transform the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectB.data_handling.transforms.fft import FFT2D\n",
    "import torch\n",
    "\n",
    "# Apply FFT to the videos\n",
    "fft = FFT2D()\n",
    "videos_fft = fft(torch.tensor(videos))\n",
    "\n",
    "# Display the video grid\n",
    "PlotUtils.display_video_grid(\n",
    "    np.abs(videos_fft[sampled_indices]), grid_size=(4, 4), figsize=(24, 24), norm=\"log\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Randomly mask 75% of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectB.data_handling.transforms.undersampling import UniformUndersampler\n",
    "\n",
    "undersampler = UniformUndersampler(factor=0.5, hw_center=2, seed=42)\n",
    "\n",
    "videos_fft_masked = undersampler.forward(videos_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the video grid\n",
    "PlotUtils.display_video_grid(\n",
    "    np.abs(videos_fft_masked[sampled_indices]),\n",
    "    grid_size=(4, 4),\n",
    "    figsize=(24, 24),\n",
    "    norm=\"log\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inverse FFT the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_masked = np.fft.ifft2(\n",
    "    np.fft.ifftshift(videos_fft_masked, axes=(-2, -1)), axes=(-2, -1)\n",
    ")\n",
    "\n",
    "# Display the video grid\n",
    "PlotUtils.display_video_grid(\n",
    "    np.abs(videos_masked[sampled_indices]), grid_size=(4, 4), figsize=(24, 24)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Do it all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "transforms = v2.Compose(\n",
    "    [\n",
    "        FFT2D(),\n",
    "        UniformUndersampler(factor=0.5, hw_center=2, seed=42),\n",
    "    ]\n",
    ")\n",
    "\n",
    "videos_fft_masked = transforms(torch.tensor(videos))\n",
    "\n",
    "# Display the video grid\n",
    "PlotUtils.display_video_grid(\n",
    "    np.abs(videos_fft_masked[sampled_indices]),\n",
    "    grid_size=(4, 4),\n",
    "    figsize=(24, 24),\n",
    "    norm=\"log\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
